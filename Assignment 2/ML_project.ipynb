{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names = [\"attribute 1\",\"attribute 2\", \"attribute 3\", \"attribute 4\",\"attribute 5\",\"attribute 6\",\"attribute 7\",\"attribute 8\",\"attribute 9\",\"attribute 10\",\"attribute 11\",\"attribute 12\",\"attribute 13\",\"attribute 14\",\"attribute 15\",\"attribute 16\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names were given here as the dataset doesn't contain column names due to confidentiality of the data. All the values were also changed into meaningless symbols and alphabets to protect the confidentiality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('crx.data', names=attribute_names) #loading the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the dataset and performing data preprocessing....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute 1</th>\n",
       "      <th>attribute 2</th>\n",
       "      <th>attribute 3</th>\n",
       "      <th>attribute 4</th>\n",
       "      <th>attribute 5</th>\n",
       "      <th>attribute 6</th>\n",
       "      <th>attribute 7</th>\n",
       "      <th>attribute 8</th>\n",
       "      <th>attribute 9</th>\n",
       "      <th>attribute 10</th>\n",
       "      <th>attribute 11</th>\n",
       "      <th>attribute 12</th>\n",
       "      <th>attribute 13</th>\n",
       "      <th>attribute 14</th>\n",
       "      <th>attribute 15</th>\n",
       "      <th>attribute 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>b</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>1.25</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>a</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.00</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>394</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>a</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>2.00</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>b</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.04</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>750</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>b</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>8.29</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    attribute 1 attribute 2  attribute 3 attribute 4 attribute 5 attribute 6  \\\n",
       "0             b       30.83        0.000           u           g           w   \n",
       "1             a       58.67        4.460           u           g           q   \n",
       "2             a       24.50        0.500           u           g           q   \n",
       "3             b       27.83        1.540           u           g           w   \n",
       "4             b       20.17        5.625           u           g           w   \n",
       "..          ...         ...          ...         ...         ...         ...   \n",
       "685           b       21.08       10.085           y           p           e   \n",
       "686           a       22.67        0.750           u           g           c   \n",
       "687           a       25.25       13.500           y           p          ff   \n",
       "688           b       17.92        0.205           u           g          aa   \n",
       "689           b       35.00        3.375           u           g           c   \n",
       "\n",
       "    attribute 7  attribute 8 attribute 9 attribute 10  attribute 11  \\\n",
       "0             v         1.25           t            t             1   \n",
       "1             h         3.04           t            t             6   \n",
       "2             h         1.50           t            f             0   \n",
       "3             v         3.75           t            t             5   \n",
       "4             v         1.71           t            f             0   \n",
       "..          ...          ...         ...          ...           ...   \n",
       "685           h         1.25           f            f             0   \n",
       "686           v         2.00           f            t             2   \n",
       "687          ff         2.00           f            t             1   \n",
       "688           v         0.04           f            f             0   \n",
       "689           h         8.29           f            f             0   \n",
       "\n",
       "    attribute 12 attribute 13 attribute 14  attribute 15 attribute 16  \n",
       "0              f            g        00202             0            +  \n",
       "1              f            g        00043           560            +  \n",
       "2              f            g        00280           824            +  \n",
       "3              t            g        00100             3            +  \n",
       "4              f            s        00120             0            +  \n",
       "..           ...          ...          ...           ...          ...  \n",
       "685            f            g        00260             0            -  \n",
       "686            t            g        00200           394            -  \n",
       "687            t            g        00200             1            -  \n",
       "688            f            g        00280           750            -  \n",
       "689            t            g        00000             0            -  \n",
       "\n",
       "[690 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute 3</th>\n",
       "      <th>attribute 8</th>\n",
       "      <th>attribute 11</th>\n",
       "      <th>attribute 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.758725</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>1017.385507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.978163</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>5210.102598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>395.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       attribute 3  attribute 8  attribute 11   attribute 15\n",
       "count   690.000000   690.000000     690.00000     690.000000\n",
       "mean      4.758725     2.223406       2.40000    1017.385507\n",
       "std       4.978163     3.346513       4.86294    5210.102598\n",
       "min       0.000000     0.000000       0.00000       0.000000\n",
       "25%       1.000000     0.165000       0.00000       0.000000\n",
       "50%       2.750000     1.000000       0.00000       5.000000\n",
       "75%       7.207500     2.625000       3.00000     395.500000\n",
       "max      28.000000    28.500000      67.00000  100000.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in dataset: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Null values in dataset: {data.isna().values.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "present\n"
     ]
    }
   ],
   "source": [
    "if '?' in data.values:\n",
    "    print(\"present\")\n",
    "else:\n",
    "    print(\"not\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set containing some values as '?'. These fields will be replaced with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(\"?\",np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 67 null values after replacing '?' with 'nan'\n"
     ]
    }
   ],
   "source": [
    "print(f\"There were {data.isna().values.sum()} null values after replacing '?' with 'nan'\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean imputation is performed here to impute mean values into those missing fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 67 null values after mean imputation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/ts037vf542d73bs1l99r7tl40000gn/T/ipykernel_67419/2996714759.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data = data.fillna(data.mean())\n"
     ]
    }
   ],
   "source": [
    "data = data.fillna(data.mean())\n",
    "print(f\"There were {data.isna().values.sum()} null values after mean imputation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null values in columns with numerical data types. The null values were present in columns with object data type. These cannot be replaced using mean imputation. All the values will be replaced using the most frequent value in the respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 null values now.\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns:\n",
    "    if data[i].dtypes == \"object\":\n",
    "        data[i] = data[i].fillna(data[i].value_counts().index[0])\n",
    "print(f\"There were {data.isna().values.sum()} null values now.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate values in dataset: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Duplicate values in dataset: {data.duplicated().sum()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing label encoding to change the non numerical values to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   attribute 1   690 non-null    object \n",
      " 1   attribute 2   690 non-null    object \n",
      " 2   attribute 3   690 non-null    float64\n",
      " 3   attribute 4   690 non-null    object \n",
      " 4   attribute 5   690 non-null    object \n",
      " 5   attribute 6   690 non-null    object \n",
      " 6   attribute 7   690 non-null    object \n",
      " 7   attribute 8   690 non-null    float64\n",
      " 8   attribute 9   690 non-null    object \n",
      " 9   attribute 10  690 non-null    object \n",
      " 10  attribute 11  690 non-null    int64  \n",
      " 11  attribute 12  690 non-null    object \n",
      " 12  attribute 13  690 non-null    object \n",
      " 13  attribute 14  690 non-null    object \n",
      " 14  attribute 15  690 non-null    int64  \n",
      " 15  attribute 16  690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "for i in data.columns:\n",
    "    if data[i].dtype == \"object\":\n",
    "        data[i] = encoder.fit_transform(data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute 1</th>\n",
       "      <th>attribute 2</th>\n",
       "      <th>attribute 3</th>\n",
       "      <th>attribute 4</th>\n",
       "      <th>attribute 5</th>\n",
       "      <th>attribute 6</th>\n",
       "      <th>attribute 7</th>\n",
       "      <th>attribute 8</th>\n",
       "      <th>attribute 9</th>\n",
       "      <th>attribute 10</th>\n",
       "      <th>attribute 11</th>\n",
       "      <th>attribute 12</th>\n",
       "      <th>attribute 13</th>\n",
       "      <th>attribute 14</th>\n",
       "      <th>attribute 15</th>\n",
       "      <th>attribute 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>4.460</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>10.085</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>13.500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>197</td>\n",
       "      <td>3.375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     attribute 1  attribute 2  attribute 3  attribute 4  attribute 5  \\\n",
       "0              1          156        0.000            1            0   \n",
       "1              0          328        4.460            1            0   \n",
       "2              0           89        0.500            1            0   \n",
       "3              1          125        1.540            1            0   \n",
       "4              1           43        5.625            1            0   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "685            1           52       10.085            2            2   \n",
       "686            0           71        0.750            1            0   \n",
       "687            0           97       13.500            2            2   \n",
       "688            1           20        0.205            1            0   \n",
       "689            1          197        3.375            1            0   \n",
       "\n",
       "     attribute 6  attribute 7  attribute 8  attribute 9  attribute 10  \\\n",
       "0             12            7         1.25            1             1   \n",
       "1             10            3         3.04            1             1   \n",
       "2             10            3         1.50            1             0   \n",
       "3             12            7         3.75            1             1   \n",
       "4             12            7         1.71            1             0   \n",
       "..           ...          ...          ...          ...           ...   \n",
       "685            4            3         1.25            0             0   \n",
       "686            1            7         2.00            0             1   \n",
       "687            5            2         2.00            0             1   \n",
       "688            0            7         0.04            0             0   \n",
       "689            1            3         8.29            0             0   \n",
       "\n",
       "     attribute 11  attribute 12  attribute 13  attribute 14  attribute 15  \\\n",
       "0               1             0             0            68             0   \n",
       "1               6             0             0            11           560   \n",
       "2               0             0             0            96           824   \n",
       "3               5             1             0            31             3   \n",
       "4               0             0             2            37             0   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "685             0             0             0            90             0   \n",
       "686             2             1             0            67           394   \n",
       "687             1             1             0            67             1   \n",
       "688             0             0             0            96           750   \n",
       "689             0             1             0             0             0   \n",
       "\n",
       "     attribute 16  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "685             1  \n",
       "686             1  \n",
       "687             1  \n",
       "688             1  \n",
       "689             1  \n",
       "\n",
       "[690 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data is transformed into numeric by performing label encoding. Splitting the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('attribute 16',axis=1) #splitting the data other than target variable as X\n",
    "y = data['attribute 16'] #splitting the target variable as y\n",
    "\n",
    "scaler = MinMaxScaler() #scaling the data\n",
    "scaled_x = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning hyperparameters for logistic regression and implementing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: LogisticRegression(C=0.1, solver='liblinear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vamsishree/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.86116838 0.86121134 0.86945876        nan 0.85910653\n",
      " 0.85496134 0.8570232         nan 0.85081615 0.85493986 0.85285653]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parameter_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['lbfgs', 'liblinear']}\n",
    "lr = LogisticRegression()\n",
    "gs = GridSearchCV(lr,param_grid=parameter_grid,cv=5,n_jobs=-1)\n",
    "gs.fit(X_train,y_train)\n",
    "print(f\"best estimator: {gs.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression: 0.8454106280193237\n",
      "F1 score of logistic regression: 0.8476190476190476\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=0.1,solver='liblinear')\n",
    "lr.fit(X_train,y_train)\n",
    "pred = lr.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test,pred)\n",
    "f1score_lr = f1_score(y_test,pred)\n",
    "print(f\"Accuracy of logistic regression: {accuracy_lr}\")\n",
    "print(f\"F1 score of logistic regression: {f1score_lr}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning hyperparameters for support vector machine and implementing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "parameter_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "svc = SVC()\n",
    "gs = GridSearchCV(svc,param_grid=parameter_grid,cv=5,n_jobs=-1)\n",
    "gs.fit(X_train,y_train)\n",
    "\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of support vector machine: 0.8405797101449275\n",
      "F1 score of support vector machine: 0.8374384236453202\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=0.1,kernel='linear')\n",
    "svc.fit(X_train,y_train)\n",
    "pred_svc = svc.predict(X_test)\n",
    "accuracy_svc = accuracy_score(y_test,pred_svc)\n",
    "f1score_svc = f1_score(y_test,pred_svc)\n",
    "print(f\"Accuracy of support vector machine: {accuracy_svc}\")\n",
    "print(f\"F1 score of support vector machine: {f1score_svc}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning hyperparameters for random forest classification and implementing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=7, max_features='sqrt', min_samples_leaf=3,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "parameter_grid = {'n_estimators': [100, 200, 500], 'max_depth': [3, 5, 7], 'max_features': ['sqrt', 'log2'], 'min_samples_leaf': [1, 3, 5], 'min_samples_split': [2, 4, 6]}\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "gs = GridSearchCV(rf,param_grid=parameter_grid,cv=5,n_jobs=-1)\n",
    "gs.fit(X_train,y_train)\n",
    "\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of support vector machine: 0.8743961352657005\n",
      "F1 score of support vector machine: 0.8828828828828829\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state= 42, max_depth=7,max_features='sqrt',min_samples_leaf=3)\n",
    "rf.fit(X_train,y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test,pred_rf)\n",
    "f1score_rf = f1_score(y_test,pred_rf)\n",
    "print(f\"Accuracy of support vector machine: {accuracy_rf}\")\n",
    "print(f\"F1 score of support vector machine: {f1score_rf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['LR', 'SVM', 'RF']\n",
    "acc = [accuracy_lr,accuracy_svc,accuracy_rf]\n",
    "f1 = [f1score_lr,f1score_svc,f1score_rf]\n",
    "figure, axis = plt.subplots()\n",
    "axis.set_xlabel('Model')\n",
    "axis.set_ylabel('Accuracy,F1 Score')\n",
    "axis.set_title('Comparision of accuracy and f1 score')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.yticks([0.8, 0.85, 0.9, 0.95, 1.0])\n",
    "x_position = np.arange(len(labels))\n",
    "axis.set_xticks(x_position)\n",
    "axis.set_xticklabels(labels)\n",
    "axis.bar(x_position - 0.1, acc, width=0.2, color='red', label='Accuracy')\n",
    "axis.bar(x_position + 0.1, f1, width=0.2, color='green', label='F1 Score')\n",
    "axis.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
